<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Protein-Ligand Binding Site Prediction | About Myself</title> <meta name="author" content="Roshan "> <meta name="description" content="Predicting the binding site of a ligand on a protein is a crucial step in drug discovery. This project aims to predict the binding site of a ligand on a protein using a segmentation based deep learning model."> <meta name="keywords" content="academic-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://roshanmsb.github.io/blog/2020/protein-binding/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Protein-Ligand Binding Site Prediction",
      "description": "Predicting the binding site of a ligand on a protein is a crucial step in drug discovery. This project aims to predict the binding site of a ligand on a protein using a segmentation based deep learning model.",
      "published": "November 16, 2020",
      "authors": [
        {
          "author": "Roshan",
          "authorURL": "",
          "affiliations": [
            {
              "name": "IIT Madras",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">About Myself</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Protein-Ligand Binding Site Prediction</h1> <p>Predicting the binding site of a ligand on a protein is a crucial step in drug discovery. This project aims to predict the binding site of a ligand on a protein using a segmentation based deep learning model.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#traditional-approaches">Traditional Approaches</a></div> <div><a href="#methodology">Methodology</a></div> <div><a href="#conclusion">Conclusion</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Inferring knowledge from highly complex and high-dimensional data has always been a challenge in biology. Recently, deep-learning algorithms have taken the world by storm, achieving state-of-the-art results in various tasks like image classification, speech recognition, language translation and object detection. Deep learning algorithms take in raw inputs defined with a set of features and give predictions for the given task based on patterns buried inside. These algorithms perform exceptionally well with a massive amount of data. Since biology is a data-rich field with complex and unstructured data, scientists can apply deep learning for almost all tasks related to biology, potentially revolutionising this field. Deep learning approaches have already improved over previous scores achieved using traditional methods in specific tasks, although the gains in some studies are modest. This method can answer a biological or medical question, identifying essential features and predicting outcomes by harnessing heterogeneity across several dimensions of natural variation. Computer-aided drug design aims to make the drug discovery process faster and cheaper. Current research focuses more on the docking and scoring part of the drug discovery pipeline. However, these methodologies already assume that the protein’s binding site is already determined with high confidence. Accurate binding site detection is complex, and current methods are lacking in locating the druggable binding sites with high accuracy.</p> <h2 id="traditional-approaches">Traditional Approaches</h2> <p>Traditional approaches for binding cavity detection are typically geometry-based, but there are also examples of tools using binding energy to different chemical probes, sequence conservation (template or evolutionary methods) or a combination of these. For example, the ProBiS<d-cite key="konc2010probis"></d-cite>, a similarity-based tool, uses local surface alignment with sub-residue precision, allowing us to find sites with similar physicochemical properties to the templates stored in the database. Such methods simultaneously detect binding sites and provide insight into their expected properties (they are probably similar to the templates in which they were matched <img class="emoji" title=":cry:" alt=":cry:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f622.png" height="20" width="20"> <img class="emoji" title=":disappointed:" alt=":disappointed:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f61e.png" height="20" width="20">). Other approaches rely on a two-step algorithm, in which potential pockets are first identified and then scored to select the most probable binding sites. For example, Fpocket<d-cite key="le2009fpocket"></d-cite> is a geometry-based method that finds cavities in a protein’s structure and then scores them. The reverse approach is used in P2RANK<d-cite key="krivak2018p2rank"></d-cite>, which uses a random forest (RF) model to predict the “inaudibility” score for each point on a protein’s surface and cluster points with high scores. The method discussed here developed by Stepniewska-Dziubinska, Marta M., Piotr Zielenkiewicz, and Pawel Siedlecki.<d-cite key="stepniewska2020improving"></d-cite> uses 3D convolution layers to classify each atom in the protein space, whether it belongs to a binding site or not, similar to a 3D segmentation task. Predictions can then be saved as .cmap or .cube files that can be later analyzed in molecular modelling software.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/segmentation-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/segmentation-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/segmentation-1400.webp"></source> <img src="/assets/img/segmentation.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A picture showing the difference between classification and segmentation. </div> <h2 id="methodology">Methodology</h2> <p>The scPDB database<d-cite key="meslamani2011sc"></d-cite> which contains 16034 annotated druggable binding sites from 4782 proteins and 6326 ligands was used for training the deep learning model. The dataset contained protein structures originating from 952 different organisms, from which the most abundant were human (34.4%), E. coli (5.6%), Human immunodeficiency virus (4.2%), rat (2.9%), and mouse (2.4%). The input and output of the model were represented as 3D grids where each voxel in the grid contained 18 features extracted from individual atoms for the input using open babel python package.</p> <details><summary>The 18 features used to describe an atom are:</summary> <ol> <li>9 bits (one-hot or all null) encoding atom types: B, C, N, O, P, S, Se, halogen and metal</li> <li>1 integer (1, 2, or 3) with atom hybridization: hyb</li> <li>1 integer counting the numbers of bonds with other heavy atoms: heavy_valence</li> <li>1 integer counting the numbers of bonds with other heteroatoms: hetero_valence</li> <li>5 bits (1 if present) encoding properties defined with SMARTS patterns: hydrophobic, aromatic, acceptor, donor and ring</li> <li>1 float with partial charge: partialcharge</li> </ol> </details> <p>The output grid was also of the same size, centre and resolution but with binary masks for the presence of site atoms instead of atomic features. The output grid was converted to 3D probability densities for loss calculation. The input grid was of the shape (18,36,36,36) while the output grid was of the shape (1,36,36,36).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/protein-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/protein-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/protein-1400.webp"></source> <img src="/assets/img/protein.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/binding_site-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/binding_site-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/binding_site-1400.webp"></source> <img src="/assets/img/binding_site.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Input protein grid (left) and output binding site grid (right) for the deep learning model. </div> <p>Deep learning model used is similar to the U-net architecture modified for the binding site prediction task. The model contains an encoder and a decoder network where the encoder compresses the input representation into a latent space and the decoder makes predictions based on the latent space which can localize features for highly accurate predictions. The model was developed using the PyTorch framework containing 4 encoder and 4 decoder blocks with one convolutional block in the bottleneck latent space. All the 2D blocks used in the original U-net architecture were modified to 3D blocks as the input was a 3D grid. Each block consists of two convolutional layers with the same number of filters (32, 64, 128, 256, or 512), kernel size of 3×3×3 pixels and ReLU activation function, combined either with a max-pooling layer or with an up-sampling layer. The two first max-pooling layers and the two last up-sampling layers have 2×2×2 patch sizes, while layers in the middle have 3x3x3 patch sizes. The feature maps in the middle of the network have spatial sizes of 1×1×1 and can be used as feature vectors. The model was trained with a batch size of 32 for 100 epochs after which the dice loss didn’t converge. Dice loss was used as the loss function for backpropagation of the neural network. Discretized volume overlap (DVO) was used as the metric for evaluation which is used to determine whether the predicted site is similar to the binding site or not. The dataset was split into a training and test set and the model achieved a DVO score of 0.623 on the test set.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/unet-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/unet-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/unet-1400.webp"></source> <img src="/assets/img/unet.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> U-net architecture used for the binding site prediction task. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/input-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/input-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/input-1400.webp"></source> <img src="/assets/img/input.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/predict-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/predict-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/predict-1400.webp"></source> <img src="/assets/img/predict.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Input protein (left) and predicted binding site (right). </div> <h2 id="conclusion">Conclusion</h2> <p>The inference can be done using a CPU and enables fast detection of single or multiple binding sites in just under 10 seconds. Deep learning methods gained popularity in recent years because of their flexibility and potential for capturing complex relationships hidden in the data. Therefore, this work can also be seen as an example of adapting deep learning methods developed in other fields to structural bioinformatics.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2020-11-16-protein-binding.bib"></d-bibliography><div id="giscus_thread" style="max-width: 1000px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0" style="text-align: center;"> © Copyright 2023 Roshan . Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: September 11, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-LX70P2JRCV"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-LX70P2JRCV");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>